{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdedf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec87a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akakce (2694, 7)\n",
      "amazon (1374, 7)\n",
      "arabam (2824, 7)\n",
      "donanimhaber (754, 7)\n",
      "haberturk (24000, 7)\n",
      "mgm (570, 7)\n",
      "nefisyemektarifleri (756, 7)\n",
      "pazarama (4104, 7)\n",
      "trendyol (5402, 7)\n",
      "(42478, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url1</th>\n",
       "      <th>url2</th>\n",
       "      <th>url1_dir</th>\n",
       "      <th>url2_dir</th>\n",
       "      <th>pair</th>\n",
       "      <th>identical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.akakce.com/elektrikli-bisiklet/iki...</td>\n",
       "      <td>https://www.akakce.com/info/hakkimizda.asp</td>\n",
       "      <td>www.akakce.com/67</td>\n",
       "      <td>www.akakce.com/83</td>\n",
       "      <td>searchhak</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.akakce.com/cocuk-giyim-aksesuar.html</td>\n",
       "      <td>https://www.akakce.com/info/hakkimizda.asp</td>\n",
       "      <td>www.akakce.com/75</td>\n",
       "      <td>www.akakce.com/83</td>\n",
       "      <td>serach1hak</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.akakce.com/televizyon/en-ucuz-sams...</td>\n",
       "      <td>https://www.akakce.com/magaza/vivensecom.html</td>\n",
       "      <td>www.akakce.com/31</td>\n",
       "      <td>www.akakce.com/74</td>\n",
       "      <td>itemstore</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.akakce.com/elektrikli-bisiklet/en-...</td>\n",
       "      <td>https://www.akakce.com/magaza/ciceksepeti.html</td>\n",
       "      <td>www.akakce.com/39</td>\n",
       "      <td>www.akakce.com/73</td>\n",
       "      <td>itemstore</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.akakce.com/saat-giyim-aksesuar.html</td>\n",
       "      <td>https://www.akakce.com/en-cok-takip-edilen-uru...</td>\n",
       "      <td>www.akakce.com/76</td>\n",
       "      <td>www.akakce.com/87</td>\n",
       "      <td>serach1kam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                url1  \\\n",
       "0  https://www.akakce.com/elektrikli-bisiklet/iki...   \n",
       "1   https://www.akakce.com/cocuk-giyim-aksesuar.html   \n",
       "2  https://www.akakce.com/televizyon/en-ucuz-sams...   \n",
       "3  https://www.akakce.com/elektrikli-bisiklet/en-...   \n",
       "4    https://www.akakce.com/saat-giyim-aksesuar.html   \n",
       "\n",
       "                                                url2           url1_dir  \\\n",
       "0         https://www.akakce.com/info/hakkimizda.asp  www.akakce.com/67   \n",
       "1         https://www.akakce.com/info/hakkimizda.asp  www.akakce.com/75   \n",
       "2      https://www.akakce.com/magaza/vivensecom.html  www.akakce.com/31   \n",
       "3     https://www.akakce.com/magaza/ciceksepeti.html  www.akakce.com/39   \n",
       "4  https://www.akakce.com/en-cok-takip-edilen-uru...  www.akakce.com/76   \n",
       "\n",
       "            url2_dir        pair  identical  \n",
       "0  www.akakce.com/83   searchhak      False  \n",
       "1  www.akakce.com/83  serach1hak      False  \n",
       "2  www.akakce.com/74   itemstore      False  \n",
       "3  www.akakce.com/73   itemstore      False  \n",
       "4  www.akakce.com/87  serach1kam      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites=[\"akakce\",\"amazon\",\"arabam\",\"donanimhaber\",\"haberturk\",\"mgm\",\"nefisyemektarifleri\",\"pazarama\",\"trendyol\"]\n",
    "\n",
    "datas=[]\n",
    "for website in websites:\n",
    "    data=pd.read_csv(website+\"_paired.csv\",encoding='latin1')\n",
    "    # Perform random under sampling\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    data_rus, _ = rus.fit_resample(data, data[\"identical\"])\n",
    "    data_rus.reset_index(inplace=True)\n",
    "    print(website,data_rus.shape)\n",
    "    datas.append(data_rus)\n",
    "data=pd.concat(datas,ignore_index=True).drop(\"index\",axis=1)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9764fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " resnet50 (Functional)          (None, 8, 8, 2048)   23587712    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['resnet50[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['resnet50[1][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4096)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 , 'global_average_pooling2d_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2048)         8390656     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2049        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,980,417\n",
      "Trainable params: 31,927,297\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Input shapes\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# Define two input layers\n",
    "input_1 = Input(shape=input_shape, name='input_1')\n",
    "input_2 = Input(shape=input_shape, name='input_2')\n",
    "\n",
    "# Option 1: Share the same ResNet model (shared weights)\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "# Freeze the base model (optional, for feature extraction)\n",
    "base_model.trainable = True\n",
    "\n",
    "# Apply the same model to both inputs\n",
    "features_1 = base_model(input_1)\n",
    "features_2 = base_model(input_2)\n",
    "\n",
    "# Option 2: Use separate ResNet models (unshared weights)\n",
    "# base_model_1 = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "# base_model_2 = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "# base_model_1.trainable = False\n",
    "# base_model_2.trainable = False\n",
    "# features_1 = base_model_1(input_1)\n",
    "# features_2 = base_model_2(input_2)\n",
    "\n",
    "# Pool the features\n",
    "pool_1 = GlobalAveragePooling2D()(features_1)\n",
    "pool_2 = GlobalAveragePooling2D()(features_2)\n",
    "\n",
    "# Combine features\n",
    "combined = Concatenate()([pool_1, pool_2])\n",
    "\n",
    "# Classification head\n",
    "x = Dense(2048, activation='relu')(combined)\n",
    "output = Dense(1, activation='sigmoid')(x) # Binary classification\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3,decay=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbfccca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "850/850 [==============================] - 575s 660ms/step - loss: 0.2731 - accuracy: 0.8839 - val_loss: 0.2948 - val_accuracy: 0.9229\n",
      "Epoch 2/30\n",
      "850/850 [==============================] - 561s 660ms/step - loss: 0.0919 - accuracy: 0.9653 - val_loss: 0.2235 - val_accuracy: 0.9079\n",
      "Epoch 3/30\n",
      "850/850 [==============================] - 559s 658ms/step - loss: 0.0518 - accuracy: 0.9812 - val_loss: 0.0493 - val_accuracy: 0.9841\n",
      "Epoch 4/30\n",
      "850/850 [==============================] - 567s 667ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.0342 - val_accuracy: 0.9903\n",
      "Epoch 5/30\n",
      "850/850 [==============================] - 557s 655ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.0358 - val_accuracy: 0.9860\n",
      "Epoch 6/30\n",
      "850/850 [==============================] - 558s 657ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0188 - val_accuracy: 0.9938\n",
      "Epoch 7/30\n",
      "850/850 [==============================] - 560s 659ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0197 - val_accuracy: 0.9940\n",
      "Epoch 8/30\n",
      "850/850 [==============================] - 574s 675ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0228 - val_accuracy: 0.9926\n",
      "Epoch 9/30\n",
      "850/850 [==============================] - 574s 675ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0244 - val_accuracy: 0.9910\n",
      "Epoch 10/30\n",
      "850/850 [==============================] - 544s 640ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0151 - val_accuracy: 0.9946\n",
      "Epoch 11/30\n",
      "850/850 [==============================] - 554s 652ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0099 - val_accuracy: 0.9979\n",
      "Epoch 12/30\n",
      "850/850 [==============================] - 567s 667ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 13/30\n",
      "850/850 [==============================] - 568s 668ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0995 - val_accuracy: 0.9795\n",
      "Epoch 14/30\n",
      "850/850 [==============================] - 569s 669ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
      "Epoch 15/30\n",
      "850/850 [==============================] - 571s 672ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0143 - val_accuracy: 0.9971\n",
      "Epoch 16/30\n",
      "741/850 [=========================>....] - ETA: 1:09 - loss: 0.0025 - accuracy: 0.9992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m make_dataset(test_img1, test_img2, test_labels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Superuser\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_image(path, img_size=(256, 256)):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=3)  # use decode_png for PNGs\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)  # normalize for ResNet\n",
    "    return image\n",
    "\n",
    "def make_dataset(image_paths_1, image_paths_2, labels, batch_size=32, shuffle=True):\n",
    "    path_ds_1 = tf.data.Dataset.from_tensor_slices(image_paths_1)\n",
    "    path_ds_2 = tf.data.Dataset.from_tensor_slices(image_paths_2)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "\n",
    "    def process_pair(path1, path2, label):\n",
    "        img1 = load_and_preprocess_image(\"data/\"+path1+\"/ss.png\")\n",
    "        img2 = load_and_preprocess_image(\"data/\"+path2+\"/ss.png\")\n",
    "        return {'input_1': img1, 'input_2': img2}, label\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((path_ds_1, path_ds_2, label_ds))\n",
    "    dataset = dataset.map(process_pair, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(labels))\n",
    "\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_img1, test_img1, train_img2, test_img2, train_labels, test_labels = train_test_split(\n",
    "    data[\"url1_dir\"].to_numpy(), data[\"url2_dir\"].to_numpy(), data[\"identical\"].to_numpy(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "train_img1, val_img1, train_img2, val_img2, train_labels, val_labels = train_test_split(\n",
    "    train_img1, train_img2, train_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    ")\n",
    "train_dataset = make_dataset(train_img1, train_img2, train_labels, batch_size=32, shuffle=False)\n",
    "val_dataset = make_dataset(val_img1, val_img2, val_labels, batch_size=32, shuffle=False)\n",
    "test_dataset = make_dataset(test_img1, test_img2, test_labels, batch_size=32, shuffle=False)\n",
    "# Train the model\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5897f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAF2CAYAAAAcHvCGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA92ElEQVR4nO3de3wU5aE38N/sNZvbhpALiSQQqQUVBIuK6Kli4dUiIlqtAnqk6NFTRS3o8QjnHLy1Nl5qS1WKR89boG8FFCtY6UFFBDx6RA1IFZUoGiQQknDLbm57nef9Y3Ymu7lvdnZnYH/fz2c+Ozszu/NkWZ3fPreRhBACRERElJYsRheAiIiIjMMgQERElMYYBIiIiNIYgwAREVEaYxAgIiJKYwwCREREaYxBgIiIKI0xCBAREaUxBgEiIqI0xiBARJAkCQ899FDcr9u3bx8kScKKFSt6PW7r1q2QJAlbt24dUPmIKHkYBIhMYsWKFZAkCZIk4b333uuyXwiBsrIySJKEK664woASEtHJiEGAyGQyMjKwatWqLtu3bduGAwcOwOl0GlAqIjpZMQgQmczll1+OtWvXIhQKxWxftWoVxo8fjyFDhhhUMiI6GTEIEJnMrFmzcPToUWzatEnbFggE8Morr2D27Nndvqa1tRX33nsvysrK4HQ6MXLkSPzmN79B55uL+v1+LFiwAIWFhcjJycGVV16JAwcOdPueBw8exM0334zi4mI4nU6ceeaZ+OMf/6jfHwpg7dq1GD9+PFwuFwoKCnDjjTfi4MGDMcfU19dj7ty5GDp0KJxOJ0pKSjBjxgzs27dPO6aqqgqXXXYZCgoK4HK5UFFRgZtvvlnXshKdrGxGF4CIYg0fPhwTJ07E6tWrMXXqVADAxo0b4fF4MHPmTDz99NMxxwshcOWVV2LLli245ZZbMG7cOLz55pu47777cPDgQfzud7/Tjv2nf/on/PnPf8bs2bNxwQUX4J133sG0adO6lKGhoQHnn38+JEnCnXfeicLCQmzcuBG33HILvF4v5s+fn/DfuWLFCsydOxfnnnsuKisr0dDQgN///vd4//338cknnyAvLw8AcM011+Dzzz/HXXfdheHDh6OxsRGbNm3C/v37teeXXnopCgsLsXDhQuTl5WHfvn149dVXEy4jUVoQRGQKy5cvFwDExx9/LJ599lmRk5Mj2trahBBC/PSnPxWXXHKJEEKIYcOGiWnTpmmvW79+vQAgfvWrX8W837XXXiskSRJ79+4VQgixa9cuAUDccccdMcfNnj1bABAPPvigtu2WW24RJSUl4siRIzHHzpw5U7jdbq1cNTU1AoBYvnx5r3/bli1bBACxZcsWIYQQgUBAFBUVidGjR4v29nbtuA0bNggA4oEHHhBCCHH8+HEBQDz55JM9vve6deu0z42I4semASITuu6669De3o4NGzagubkZGzZs6LFZ4L//+79htVpx9913x2y/9957IYTAxo0bteMAdDmu8697IQT+8pe/YPr06RBC4MiRI9py2WWXwePxYOfOnQn9fVVVVWhsbMQdd9yBjIwMbfu0adMwatQo/O1vfwMAuFwuOBwObN26FcePH+/2vdSagw0bNiAYDCZULqJ0xCBAZEKFhYWYMmUKVq1ahVdffRXhcBjXXnttt8d+9913KC0tRU5OTsz2008/XduvPlosFowYMSLmuJEjR8Y8P3z4MJqamvD888+jsLAwZpk7dy4AoLGxMaG/Ty1T53MDwKhRo7T9TqcTjz/+ODZu3Iji4mJcdNFFeOKJJ1BfX68df/HFF+Oaa67Bww8/jIKCAsyYMQPLly+H3+9PqIxE6YJ9BIhMavbs2bj11ltRX1+PqVOnar98k02WZQDAjTfeiDlz5nR7zFlnnZWSsgBKjcX06dOxfv16vPnmm1i8eDEqKyvxzjvv4Oyzz4YkSXjllVewfft2vP7663jzzTdx880346mnnsL27duRnZ2dsrISnYhYI0BkUldffTUsFgu2b9/eY7MAAAwbNgx1dXVobm6O2b5nzx5tv/ooyzK++eabmOOqq6tjnqsjCsLhMKZMmdLtUlRUlNDfppap87nVbep+1YgRI3Dvvffirbfewu7duxEIBPDUU0/FHHP++efj0UcfRVVVFV588UV8/vnnWLNmTULlJEoHDAJEJpWdnY1ly5bhoYcewvTp03s87vLLL0c4HMazzz4bs/13v/sdJEnSRh6oj51HHSxZsiTmudVqxTXXXIO//OUv2L17d5fzHT58eCB/ToxzzjkHRUVFeO6552Kq8Ddu3Igvv/xSG8nQ1tYGn88X89oRI0YgJydHe93x48e7DJMcN24cALB5gKgf2DRAZGI9Vc1Hmz59Oi655BL8+7//O/bt24exY8firbfewmuvvYb58+drfQLGjRuHWbNm4Q9/+AM8Hg8uuOACbN68GXv37u3yno899hi2bNmCCRMm4NZbb8UZZ5yBY8eOYefOnXj77bdx7NixhP4uu92Oxx9/HHPnzsXFF1+MWbNmacMHhw8fjgULFgAAvvrqK0yePBnXXXcdzjjjDNhsNqxbtw4NDQ2YOXMmAGDlypX4wx/+gKuvvhojRoxAc3MzXnjhBeTm5uLyyy9PqJxEacHYQQtEpIoePtibzsMHhRCiublZLFiwQJSWlgq73S5OO+008eSTTwpZlmOOa29vF3fffbcYPHiwyMrKEtOnTxe1tbVdhg8KIURDQ4OYN2+eKCsrE3a7XQwZMkRMnjxZPP/889oxAx0+qHrppZfE2WefLZxOp8jPzxc33HCDOHDggLb/yJEjYt68eWLUqFEiKytLuN1uMWHCBPHyyy9rx+zcuVPMmjVLlJeXC6fTKYqKisQVV1whqqqqei0TESkkITrVqREREVHaYB8BIiKiNMYgQERElMYYBIiIiNIYgwAREVEaYxAgIiJKYwwCREREacx0EwrJsoy6ujrk5ORAkiSji0NERHTCEEKgubkZpaWlsFj691vfdEGgrq4OZWVlRheDiIjohFVbW4uhQ4f261jTBQH1Vqq1tbXIzc01uDREREQnDq/Xi7Kysi63Je+N6YKA2hyQm5vLIEBERDQA8TSts7MgERFRGmMQICIiSmMMAkRERGnMdH0EiIiI0lk4HEYwGOxxv8Ph6PfQwP5gECAiIjIBIQTq6+vR1NTU63EWiwUVFRVwOBy6nJdBgIiIyATUEFBUVITMzMxue/6rk+4dOnQI5eXluky8xyBARERksHA4rIWAwYMH93psYWEh6urqEAqFYLfbEz43OwsSEREZTO0TkJmZ2eexapNAOBzW5dwMAkRERCbRn6p+ve/DwyBARESUxhgEkqW5AVj7M6Dmf4wuCRERUY/YWTBZ9rwOfL4OCAeBih8aXRoiIqJusUYgWXwe5bG9ydBiEBER9YZBIFn8zZFHr7HlICKiE4Ysy30eI4TQ9ZxsGkgWBgEiIuonddrguro6FBYWwuFwdDs6QAiBw4cPQ5IkXeYQABgEkkcLAs3GloOIiExPnTb40KFDqKur6/VYSZIwdOhQWK1WXc7NIJAsagDweQEhAJ3HfRIR0cnF4XCgvLwcoVCo18mC7Ha7biEAYBBIHjUIyEEg5APsLmPLQ0REpqdW+etV7d8f7CyYLNF9A9g8QEREJsUgkCzRF38fOwwSEZE5MQgkS3QQ4MgBIiIyKQaBZGEQICKiEwCDQDKEAkoHQRWbBoiIyKQYBJIh0BL7nJ0FiYjIpBgEkqHzhZ9NA0REZFIMAsnQJQiwRoCIiMyJQSAZOl/41TsREhERmQyDQDKwaYCIiE4QDALJ0PnCz6YBIiIyqbiDwLvvvovp06ejtLQUkiRh/fr12r5gMIj7778fY8aMQVZWFkpLS3HTTTf1eSelk06XpgHWCBARkTnFHQRaW1sxduxYLF26tMu+trY27Ny5E4sXL8bOnTvx6quvorq6GldeeaUuhT1hqEHAkRP7nIiIyGTivvvg1KlTMXXq1G73ud1ubNq0KWbbs88+i/POOw/79+9HeXn5wEp5olEv/LmlwJFq9hEgIiLTSnofAY/HA0mSkJeXl+xTmYcaBNynKI9sGiAiIpOKu0YgHj6fD/fffz9mzZqF3Nzcbo/x+/3w+/3ac6/3JLhoRtcIRD8nIiIymaTVCASDQVx33XUQQmDZsmU9HldZWQm3260tZWVlySpS6qhNAblDlcdAMyCHjSsPERFRD5ISBNQQ8N1332HTpk091gYAwKJFi+DxeLSltrY2GUVKrc5NA0DX+w8QERGZgO5NA2oI+Prrr7FlyxYMHjy41+OdTiecTqfexTCWGgQyCwCrAwgHlH4CGW5jy0VERNRJ3EGgpaUFe/fu1Z7X1NRg165dyM/PR0lJCa699lrs3LkTGzZsQDgcRn19PQAgPz8fDodDv5KbmRoEnDmAMxdoO8KRA0REZEpxB4Gqqipccskl2vN77rkHADBnzhw89NBD+Otf/woAGDduXMzrtmzZgkmTJg28pCcStRnAmaMsbUfYYZCIiEwp7iAwadIkCCF63N/bvrQRXSOQEekfwSGERERkQrzXgN5kOSoI5CoLwKYBIiIyJQYBvQVbAURqRdQ+AgCDABERmRKDgN7U2gCLHbA52TRARESmxiCgN61ZIBuQJKVWIHo7ERGRiTAI6C26oyDApgEiIjI1BgG9qRd8NQCoTQOsESAiIhNiENBblxqByCP7CBARkQkxCOiNTQNERHQCYRDQG4MAERGdQBgE9NY5CHD4IBERmRiDgN60zoKdawTYWZCIiMyHQUBv0dMLA1HzCLBGgIiIzIdBQG89NQ2EA0DQZ0yZiIiIesAgoDd/1C2IAcCRHbWPzQNERGQuDAJ661wjYLECDjYPEBGROTEI6K1zEACiZhdkECAiInNhENCberF3RAUBzi5IREQmxSCgt+5qBDipEBERmRSDgJ6E6CEI8FbERERkTgwCegr5ATmorHfXR4BNA0REZDIMAnqK/sUfPWyQswsSEZFJMQjoKbqjoCXqo9WaBjypLxMREVEvGAT01F3/AADIcCuPbBogIiKTYRDQU09BgJ0FiYjIpBgE9NRjEODwQSIiMicGAT312DTAzoJERGRODAJ6Un/x99Q0wD4CRERkMgwCegqodx7Mjd3OpgEiIjIpBgE99dlHgE0DRERkLgwCeupPHwFZTm2ZiIiIesEgoCctCGTHbteaCkRH8wEREZEJMAjoqacaAZsTsNgjx7CfABERmUfcQeDdd9/F9OnTUVpaCkmSsH79+pj9Qgg88MADKCkpgcvlwpQpU/D111/rVV5z00YNdOosKEm88RAREZlS3EGgtbUVY8eOxdKlS7vd/8QTT+Dpp5/Gc889hw8//BBZWVm47LLL4PP5Ei6s6fVUIxC9jR0GiYjIRGzxvmDq1KmYOnVqt/uEEFiyZAn+4z/+AzNmzAAA/OlPf0JxcTHWr1+PmTNnJlZas+s1CHAIIRERmY+ufQRqampQX1+PKVOmaNvcbjcmTJiADz74QM9TmVNvQUC98RCDABERmUjcNQK9qa+vBwAUFxfHbC8uLtb2deb3++H3+7XnXu8JfKHsT9MA+wgQEZGJGD5qoLKyEm63W1vKysqMLtLAhENAsE1Z79xZMHobawSIiMhEdA0CQ4YMAQA0NDTEbG9oaND2dbZo0SJ4PB5tqa2t1bNIqROI6gToyO66nzceIiIiE9I1CFRUVGDIkCHYvHmzts3r9eLDDz/ExIkTu32N0+lEbm5uzHJCUi/wtgzA5ui6n00DRERkQnH3EWhpacHevXu15zU1Ndi1axfy8/NRXl6O+fPn41e/+hVOO+00VFRUYPHixSgtLcVVV12lZ7nNp7f+AQDvN0BERKYUdxCoqqrCJZdcoj2/5557AABz5szBihUr8K//+q9obW3FbbfdhqamJvzDP/wD3njjDWRkZOhXajPyq3ce7CkIqPMIsEaAiIjMI+4gMGnSJAghetwvSRIeeeQRPPLIIwkV7ITTV42AOnzQ50lNeYiIiPrB8FEDJw31l76DTQNERHTiYBDQS599BNg0QERE5sMgoJc+mwZYI0BERObDIKCX/tYIcPggERGZCIOAXvo7fDDsB0L+7o8hIiJKMQYBvaht/33VCABsHiAiItNgENCLViPQw8yIFmvH1MMcQkhERCbBIKCXvpoGAA4hJCIi02EQ0Eu/ggCHEBIRkbkwCOilP0FAHULIkQNERGQSDAJ6YdMAERGdgBgE9NJXZ0GATQNERGQ6DAJ6EAIIxNE0wCBAREQmwSCgh2AbIGRlvT9NA+wjQEREJsEgoAe1WUCyAHZXz8c5WSNARETmwiCgh+iOgpLU83G88RAREZkMg4AetOmFe+koCPDGQ0REZDoMAnroz9BBgMMHiYjIdBgE9NDvIMDhg0REZC4MAnrobxDgzIJERGQyDAJ66HeNgDv2eCIiIoMxCOhB6ywYR9OALCe3TERERP3AIKCH/kwvDHQ0DUAAwdakFomIiKg/GAT00N+mAVsGYLEp6+wnQEREJsAgoIf+BgFJ4uyCRERkKgwCeuhvEAA4uyAREZkKg4Ae/C3KY3+CAGcXJCIiE2EQ0INaze/oTxBQhxAyCBARkfEYBPQQT9MAZxckIiITYRDQw0D6CLBpgIiITIBBQA9x1QiwsyAREZkHg0CiQn4g7FfW2TRAREQnGN2DQDgcxuLFi1FRUQGXy4URI0bgl7/8JYQQep/KHNQRAwCHDxIR0QnHpvcbPv7441i2bBlWrlyJM888E1VVVZg7dy7cbjfuvvtuvU9nPPWXvT0LsFj7Pl4bPuhJXpmIiIj6Sfcg8L//+7+YMWMGpk2bBgAYPnw4Vq9ejY8++kjvU5lDPP0DAA4fJCIiU9G9aeCCCy7A5s2b8dVXXwEA/v73v+O9997D1KlT9T6VOcQbBNg0QEREJqJ7jcDChQvh9XoxatQoWK1WhMNhPProo7jhhhu6Pd7v98Pv92vPvd4T7Jdy3DUCnFmQiIjMQ/cagZdffhkvvvgiVq1ahZ07d2LlypX4zW9+g5UrV3Z7fGVlJdxut7aUlZXpXaTkijsIsEaAiIjMQ/cgcN9992HhwoWYOXMmxowZg3/8x3/EggULUFlZ2e3xixYtgsfj0Zba2lq9i5Rcalt/vDUC7CNAREQmoHvTQFtbGyyW2HxhtVohy3K3xzudTjidTr2LkTpajUBu/45X+wiEfEAoANgcySkXERFRP+geBKZPn45HH30U5eXlOPPMM/HJJ5/gt7/9LW6++Wa9T2UOA20aUF9rG6x/mYiIiPpJ9yDwzDPPYPHixbjjjjvQ2NiI0tJS/PM//zMeeOABvU9lDgH1FsTZ/TveYlXmHAi2An4PkMUgQERExtE9COTk5GDJkiVYsmSJ3m9tTvHWCABK80CwlR0GiYjIcLzXQKLi7SwIdDQPcAghEREZjEEgUfF2FgQ4coCIiEyDQSBRA20aiH4tERGRQRgEEjWQIMDZBYmIyCQYBBI1oCCg1ggwCBARkbEYBBI1oKYB3oGQiIjMgUEgEXI4ah6BAXQWZNMAEREZjEEgEWoIAAbYNMDOgkREZCwGgUSoF3KrA7DFcb8EDh8kIiKTYBBIxED6BwAcPkhERKbBIJCIgQYBzixIREQmwSCQCLVq3zHAIMCmASIiMhiDQCL86oiBgTYNMAgQEZGxGAQSMeCmAbWzYDMghL5lIiIiigODQCIS7SMgZCDQqm+ZiIiI4sAgkIiBBgG7C7DYIu/B5gEiIjIOg0Ai1It4vEFAkji7IBERmQKDQCK0GoE4phdWcXZBIiIyAQaBRAy0aQCICgIe/cpDREQUJwaBRCQSBDi7IBERmQCDQCL0qBFgHwEiIjIQg0AiEgoCvPEQEREZj0EgEYl0FmTTABERmQCDQCIGOnww+jVsGiAiIgMxCAyUEFE1Atnxv57DB4mIyARsRhcgJeo/U5aiM4DScfq8Z7AdEGFlPaFRAxw+SERExkmPGoGqPwLrbwf2/E2/9wxE7jwICbBnxf96jhogIiITSI8gkHuK8ug5oN97Ro8YsAzgY2TTABERmUB6BAF3mfLo1TMIJNBRMPp1HD5IREQGSpMgkOQagYHg8EEiIjKBNAkCQ5VHz0Glt78eEg0C7CNAREQmkB5BIKcUgASE/UDrEX3eM+EgEHldqB0IB/UpExERUZySEgQOHjyIG2+8EYMHD4bL5cKYMWNQVVWVjFP1j80BZBcr63r1E9CrRiD6vYiIiFJM9yBw/PhxXHjhhbDb7di4cSO++OILPPXUUxg0aJDep4qP3v0EEu0saLUB9kxl3ce5BIiIyBi6Tyj0+OOPo6ysDMuXL9e2VVRU6H2a+LmHAgd3KP0E9JDIfQZUzlwg2MYaASIiMozuNQJ//etfcc455+CnP/0pioqKcPbZZ+OFF17Q+zTxy1U7DNbq836JNg0AUSMH2GGQiIiMoXsQ+Pbbb7Fs2TKcdtppePPNN3H77bfj7rvvxsqVK7s93u/3w+v1xixJoY4c8OpdI5BAEOCNh4iIyGC6Nw3IsoxzzjkHv/71rwEAZ599Nnbv3o3nnnsOc+bM6XJ8ZWUlHn74Yb2L0ZXufQT0CAKcS4CIiIyle41ASUkJzjjjjJhtp59+Ovbv39/t8YsWLYLH49GW2lqdqu47i55LQA/qxdsxgDsPqji7IBERGUz3GoELL7wQ1dXVMdu++uorDBs2rNvjnU4nnE6n3sXoSu0j0HxIGbdvtSf2ftqogQQ6C7KPABERGUz3GoEFCxZg+/bt+PWvf429e/di1apVeP755zFv3jy9TxWfrELA6gAglDCQKH/k7oMJNQ24lUf2ESAiIoPoHgTOPfdcrFu3DqtXr8bo0aPxy1/+EkuWLMENN9yg96niY7EAuaXKuh79BPTsLMgaASIiMojuTQMAcMUVV+CKK65Ixlsnxl0GHN+nTz8BXYcPsrMgEREZIz3uNaDKVUcOJNghMRxU7hEAcPggERGd0NIrCOg1l0D0L3gOHyQiohNYmgUBneYSUC/cNldiow84aoCIiAyWZkGgTHlMtI+AHv0DgI4aATYNEBGRQdIrCOjVR0DvIMAaASIiMkh6BQG1j4CvqWMegIHQKwhEjxoQIrH3IiIiGoD0CgIZuR2/whPpMKjNKphojUDk9SKs3I6YiIgoxdIrCABR9xxIoMOgViOQwPTCAGDPBCSrss5+AkREZID0CwK5Oowc0IJAAjccAgBJ4uyCRERkqPQLAnrMJaBXHwGAswsSEZGh0jAI6FkjoEMQ0G485En8vYiIiOKUhkFAnUsggSAQ0DMIqE0DrBEgIqLUS78goGsfgQQ7CwKcXZCIiAyVfkEguo/AQMfu69o0wBsPERGRcdIvCOSWKo8hH9B2dGDvoWsQYGdBIiIyTvoFAZsTyC5W1gfaPJCUUQOsESAiotRLvyAAJN5PIBlNAwwCRERkgPQMAonOJaBnZ0HegZCIiAyU3kFgIHchlOUk9RFgECAiotRL8yAwgBqBYCuAyGgDzixIREQnuPQMAon0EVAv2BYbYMtIvCxsGiAiIgOlZxBQZxccSB+B6GYBSUq8LJxZkIiIDJSmQSBSI9B8CAiH4nutesF26NAsAHD4IBERGSo9g0BWEWCxA0JWwkA81Au2Hv0DgI6mgWAbEA7q855ERET9lJ5BwGLpmGEw3n4Ceo4Y6Pw+bB4gIqIUS88gAAy8n4C/RXnUKwhY7YA9M/LebB4gIqLUSuMgMMC5BPSuEYh+L9YIEBFRiqVxEFCHEMZbI5CMIMAhhEREZIw0DgJqjUC8fQR07iwY/V5sGiAiohRL3yCQq95vYKCdBXW4z4CKswsSEZFB0jcIDLhGIJlNAx793pOIiKgf0jgIRPoItB8HAq39f10ygwCbBoiIKMWSHgQee+wxSJKE+fPnJ/tU8clwd1yA4+kwmIwgwKYBIiIySFKDwMcff4z//M//xFlnnZXM0wycevOhePoJJHP4IEcNEBFRiiUtCLS0tOCGG27ACy+8gEGDBiXrNIkZSD8BbdSAjp0FnawRICIiYyQtCMybNw/Tpk3DlClTknWKxA1kLgGtRiBbv3LwxkNERGQQWzLedM2aNdi5cyc+/vjjPo/1+/3w+/3ac683hRfDeGsEhGDTABERnVR0rxGora3FL37xC7z44ovIyMjo8/jKykq43W5tKSsr07tIPYt3LoGQH5AjdwhMyqgBNg0QEVFq6R4EduzYgcbGRvzgBz+AzWaDzWbDtm3b8PTTT8NmsyEcDsccv2jRIng8Hm2prY1z7v9ExFsjEH2hdujYNKAFAc4jQEREqaV708DkyZPx2WefxWybO3cuRo0ahfvvvx9WqzVmn9PphNPp1LsY/RPdR0AIQJJ6P15tw3dkAxZr78fGg8MHiYjIILoHgZycHIwePTpmW1ZWFgYPHtxlu+HU4YOhdqDtGJA1uPfjAzrfglgVfdOh/gQSIiIinaTvzIIAYHMCWUXKen/6CSSjo2D0+4kwEGzT972JiIh6kZRRA51t3bo1FacZGPdQoLVR6SdQMrb3Y5MVBBxZgGQBhKycw5Gl7/sTERH1IL1rBID45hJIVhCQJA4hJCIiQzAIuCPDFT39GK2gzSqocxAAAKc7cg52GCQiotRhENDuNxBPjYCO0wurMjiEkIiIUo9BIJ65BJLVNBD9nmwaICKiFGIQ0IKAgX0EAM4uSEREhmAQUINAcx0QDvV+bCpqBHjjISIiSiEGgawiwGJXhu611Pd+rBoE9JxeWMXZBYmIyAAMAhYLkFuqrPfVT0AbNZCEzoLRswsSERGlCIMA0P8OgylpGuCoASIiSh0GAcAcQSCD8wgQEVHqMQgA/Z9LIBWjBtg0QEREKcQgAMRRI5Ckuw9GvydrBIiIKIUYBID+BQE5DARblfWkzizIGgEiIkodBgGgf0Eg+pe6MwnDBzmzIBERGYBBAOjoI9B+DAi0dX+MGgSsTsDm1L8MnFmQiIgMwCAAKD32HZFf5D11GExmR0G1DIDS/NDXDIdEREQ6YRAAAEkC3JFagZ6aB5IdBKLfN8BaASIiSg0GAVVf/QSSHQSsdsDmUtbZT4CIiFKEQUDV11wCyZxeWMUbDxERUYoxCKjcZcqjp7b7/VqNQBJGDKh44yEiIkoxBgGV1kfAoM6CAGcXJCKilGMQUBndRyD6vVkjQEREKcIgoIruIyBE1/2pCAJa0wDvQEhERKnBIKBSg0CwDWg/3nW/1lmQTQNERHTyYBBQ2TOArEJlvbvmAa1GIJmjBthZkIiIUotBIFpv/QQCSbzzoIo3HiIiohRjEIjW21wC7CxIREQnIQaBaL3NJcDhg0REdBJiEIjW21wCKa0RYBAgIqLUYBCI1lsfgVRMMcw+AkRElGIMAtFyI0Ggcx8BIVJUIxC5FTGbBoiIKEUYBKKpNQLeOkAOd2wPtgFCVtbZWZCIiE4iugeByspKnHvuucjJyUFRURGuuuoqVFdX632a5MguAiw2QISB5vqO7eqFWbIA9szknT+6aaC72Q2JiIh0pnsQ2LZtG+bNm4ft27dj06ZNCAaDuPTSS9Ha2qr3qfRnsQK5pcp6dD8BNQg4cgBJSt751RoBOQQE25N3HiIiogib3m/4xhtvxDxfsWIFioqKsGPHDlx00UV6n05/uUOBpv2A9wCACcq2VEwvDACObKXWQchK+HAksfaBiIgIKegj4PEoN9DJz89P9qn00d3IgVR0FASU2gYOISQiohTSvUYgmizLmD9/Pi688EKMHj2622P8fj/8fr/23Os1+ALY3VwCqQoCgDI80edhECAiopRIao3AvHnzsHv3bqxZs6bHYyorK+F2u7WlrKwsmUXqm7ubIYSpDgIAhxASEVFKJC0I3HnnndiwYQO2bNmCoUOH9njcokWL4PF4tKW2tpvpfVNJnUsgeprhlAYBNg0QEVHq6N40IITAXXfdhXXr1mHr1q2oqKjo9Xin0wmn06l3MQZO6yNgUI1ABm9FTEREqaN7EJg3bx5WrVqF1157DTk5OaivV8bju91uuFwuvU+nP7WPQNsRZQif3RUVBJI4vbCKTQNERJRCujcNLFu2DB6PB5MmTUJJSYm2vPTSS3qfKjky8pRhfIAywyBgUNMAawSIiCj5ktI0cEKTJCD3FOBItdJPYPAIg5oGWCNARETJx3sNdKdzPwEjagR8nuSfi4iI0h6DQHe0uQQikwqlNAi4Y89JRESURAwC3XFH5jLwqkFAnWI4BZ0F2TRAREQpxCDQndyeagSyk39udhYkIqIUYhDojqF9BDh8kIiIUodBoDvRNx4SgjMLEhHRSYtBoDu5pcpjsBVoaQTCkZsicWZBIiI6yTAIdMfuAjILlPXDX3Zsd6Rw1ECgBZDDyT8fERGlNQaBnqjNA417lEd7JmBN6l2bFdG1DqwVICKiJGMQ6IkaBNQagVQ0CwCAzQHYMpR19hMgIqIkYxDoSecagVQFgehzceQAERElGYNAT9S5BBpTXCMAdAwhPPBR6s5JRERpiUGgJ2qNgD8y538qg8AZM5THv/0L8MVrqTsvERGlnbQJArIc510R1SCgSsX0wqofLQbGzgZEGHjlZuDLDak7NxERpZW0CALbvz2Ky5a8iy17Gvt/m+QuQSCFNQIWCzDjWWDMdYAcAtb+DKjemLrzExFR2kiLILB0y1583diCuSs+xk1//Ah76vvRCS+7GLBEDRdMZRAAAIsVuGoZMPoaQA4CL98EfPVWastAREQnvbQIAs/O/gFuu+hUOKwW/M/XR3D57/8HC//yKRqbfT2/yGIFcko7njtScMOhzqw24OrnlT4D4QDw0o3A3rdTXw4iIjpppUUQcLvs+LfLT8fb91yMaWNKIAtgzce1mPTkVjyz+Wu0B3qYwc99Ssd6qmsEVFYbcM3/BUZdoUx1vOYG4JstxpSFiIhOOmkRBFTlgzOx9IYf4JWfT8S4sjy0BcJ4atNX+NFTW/HqzgNdOxRG9xMwKggAgNUOXLsc+P5UIOQDVs8Cat41rjxERHTSSKsgoDpneD7W3XEBnp51Nk7Jc+GQx4d7Xv47Zix9Hx9+e7TjwNzoGoEUjhrojs0BXLcSOO1SINQOrLoe2Pe+sWUiIqITXloGAQCQJAlXji3F5nsvxv0/HoVspw2fHfTg+ue345//XxVqjrSap0ZAZXMC1/0/YMRkINgGvPhTYP92o0tFREQnsLQNAqoMuxW3TxqBrfdNwo3nl8MiAW9+3oD/89ttWFMtdxxohiAAAPYMYOaLwKmTlNsk//laoPZjo0tFREQnqLQPAqqCbCd+ddUYvDn/IlwyshAhWWDlFx2dCN/+th3/+80RfHe0Ff6QwbcHtruAmauB4T8EAs3An38CHNyR+nK0HgF2/kkZzbDudmDfe0B/52kgIiJTkES/Z9hJDa/XC7fbDY/Hg9xc49rl/+frw/j96x/hFe9sAMDF/t/iOzFE21+Y48QpeS6ckudCaV4GSvNcKNWeuzAo0w5JkpJbyECr0jzw3ftAhhu46TWg9OzknvP4PmDP35TZDmu3A0KO3T/4NGD8z4Bxs4HM/OSWhYiIYgzkGsog0ItwWEb7U2fB6juOO0tWocYrUNfUDl9Q7vO1GXYLSvNcKMhyIi/TjkGZDuRlKY+DIs8HZSnreZkO5LnssFkHUEHjbwH+fI1yUc7IA+a8DpScFf/79EQIoOFzYM8G5eLf8Fns/pKxytBG70Hgs1eAQIuy3epQ5j8YPxcYdgGQ7FBEREQMAknR3qRM5pNdBAAQQuB4WxB1Te042NSOg8fbUdfUjjpPOw42+VDX1I7Dzf4BnSonw4b8LAfyMh3Iz7SjODcDRTlOFEUei3MzUJTrREG2E/bo0ODzKs0DBz4GXPnA1CeUORAyBwOZBYArT5kgqb/kMFD7ofLLf88GpRZAJVmVC/uoK4BR04C8so59/mYlDOxYDhz6e8f2gu8rtQRjZ7GWgIgoiRgETMIfCqPe48PBpnYcbw3ieFsAx1sDON4WRFNbQHmurQfhaQ/G9f6SBAzOcqAoRwkGxTkZGJoZxKzqu1Hg2d3NCyyAa5ASCjIHA1mDO0JCVmRb5mAg5Aeq/1u5r0HbkY7X2zKUkQqjpgEjp/bvYl73CVC1XAkGwVZlm9UZqSX4GWsJiIiSgEHgBBUKy/C0B2PCwdEWPxqb/Whs9qHBG1n3+nC42Y9QD3dSzEUrFtpW4/uWA8iHF/lSM/Kk1oEVKiMP+P6PgdOvAEb8CHBkDex9fF5g9ytKKKj/tGN7qmoJ2puA4zXAsRqlZuN4DeA5AOSUAMWjgeIzgSFjTr6aCiEAbx3Qfkzpx6EtomNdDnfaF7VfkoCiM2Jn1yQi02MQSAOyLHCsLYBGrx8NzT4c9vrR4PWhsVl5bGj2o8HjQ2OzD7IAbAghD63Il7wYLHkxCM3Il5qRj2bkS14UWFowxNaCAkszMixhfJd7Dr4r+hG8RechNysTuS47cl02uF12bcl22gbWEfLgTmDHithaAotNuShnDo6qnShQLswxzyP7M/KUuzNqH0hYueAdj1zoj9XErvua+le2nNJIKBitBIQhY4D8EcoUz2YmBNDSCBz+EmiMWg7vAfz9uLlWX9zlQPkEoPx8oOx8oOj0+JqZiCilGARIEwzLONzsxyFPOw55fDjU5EOdpx31Hh/qPD7Ue9rR2Owf0Gg/iwTkRkJBbobyODjbofVpKM7NiCxOFOVkwOXodOHweYHP1ip9Ceo/6/4kPZEsSj+IrALlFs1N+5U+HL3JLgYGDQcGVSiP7qFK58b6z4CG3bF9IKLZMoDCUR3hoHg0UHCaUjtic6U+JLQdi1zov1Au9OpFv/1Y98dbbMpnZbEqfTski/JLX7J0LBZr1POofSE/cLgaEJ2GyjrdQNm5SigoPx84ZTzgyEz+364XIZTvS7Bd+RtDPuXf2ZWnTNhFdIJjEKC4BMMyGpv9ONTUjjqPD41eH7ztSp8FdfH6QjHPA6G+R0x0lpth08JBUW4kKOQ4UZzjxFDrEeSGjiEz5IEreBzOwHHYfMcgtR1T+im0HVXmK2g7Bvg93Z/AYgfyyoH8io4LvrY+vO9mDZ9XuaA2fAbU71ZGSTR83lFr0ROLXZnTwe5SLib2TGXCJ3tm5Lkrar9LucCKcFSVfORRljs9D0fWhbIeaAGOfAW0NHRfDsmi/M1FpytL4SilWn/w95SpqQfK3wIcrFJmr9y/XemMqo4K0T4DmzJyRA0G5edrHWt1528BWhuVGpCWhtjHtqMdF3bt0dfpeeSxJ/YspS+Na5ASDLT1HpbMfCCryPy1RrIMePYDnoNKAAq2Ko+ByGOwTVkCbVH72jq2B9uV72J3QbJLqOy0Xw3TxWcoQfpEqGVLJiGA5nrg2LfKcrxGebz0V7Ez2SaAQYCSzhcMa2HB6+sICEdbAkrTRFRTRb3Hh/Zg/JMvWSQgy2FDptOqPWbabchxyCiytqHQ0ozBlmY4bVYEcodBcpci0+lEltOGnAwbspw2ZEeWrMh7WCxxNmXIsvIfacPnSq1B/W7lsem7uP8eXeWVKxd59WJfNErpb2F3Jf/c4RDQ+HlHMNi/HWiu63pcVpESvhxZkSCUGVlcSu2BPWpxRLbbs5QQ5fN0utBHrfcVzOImKReqsL/rfBj9fgsrkFuq/E88esmNWs9wp6ZjrBBK/5fDe5Rao8Y9SpPR4Wrlgm4GVqfynS06U2mKKz5TCQjZhfqfSwil1jDkV2qBQn7l3zoU6HgM+WK3SRbllvPOXMCZrcwo68hWlugmyd7IYeXfQb3IH/tWaaZUH0PtXV/zj+uUvlg6MFUQWLp0KZ588knU19dj7NixeOaZZ3Deeef1+ToGgZOHEALN/hAaowJCR1BQ1g83+9HqD6E1EOrX/AwDleWwKgEhQwkILrsVGXYrMuyWqPWu21x2K5x2i7aeYbMgQwoiQ/LDhQCcCMAp/HAIPxyyH1bZH/kV5VP+gw9GLRAdVfTarydrpyp69bml47nNqUzUVDhS+Z+TWQgBeGpjg0HjFwCS+NvCnqk09WQXRZZiZcnMj9TEOJWLu/YYvXTaZ7Ur/wayrPSnaD/ezdLUw/bjSpOMHOq7zI6cTkHhlI6wZM+MCk2RYOTI7ghO3QUIIYDmQx19QbSLfrUy02h3rA7AXdZ9QHN0DmadntsylO9nvB1OhawEu8YvlKXhi57DXFZhRygoOkNZd+Yo/y4+rzI02R959Hkj69HPo/b7m6Nqf3T8LqqBwJkTFRJylEd7BuA9FPmVvw+QexkJJlmVYdf5p3Yso6YptZc6ME0QeOmll3DTTTfhueeew4QJE7BkyRKsXbsW1dXVKCrqvdqQQSB9hWWB9mAYbf4QWgNhtPpDaAuE0RZQHjueK9ta/CG0+pXHFr+yv8WnPlf29TTCIlmsFgkZNgucdiucNktkUcKEy25FpsOKTKcNWQ4rMh025XlkPctphcuh7HM5lJqMLKcVTpsVIVkgGJYRCMkIhmUEw5HnYRnBUKfnUdv8oTDag2H4gnLkUV1ktAfC8IXCaA+E4Q/FPg+EZWQ7bHBndnQSzYus57rsyHM5YrZpi6UNOe0HIalVzoG22Oro7rZpVdTtQEZu7AU+qzDqwl9sriAkh5WaCs8BJRB5DiiL92DH87ajfb9Pj6SuAcFiU35V9thMZlNCY9EooPD0jsf8U42vkpdloGlfR9Obuhz7FkkNjyo1VFsdkUen0nQW/ShkpflLDRT+5q79ZPrD6ohqpoy64OdXKLV6Vrvuf57KNEFgwoQJOPfcc/Hss88CAGRZRllZGe666y4sXLiw19cyCJBehBDwh+TYwOBTah/aAzJ8wXDXi2NkvT0Yhr/Tc19QeU0gJMMfUvb7QmEEw6ZqXTOcJAHZThtynDbkZNi1WpjsDBty1XWnHTkZyjb1uCynVZsoS5IACZLyGL0O9Udy9HMJEoCwEBBCQBZKqJSFgCxDedSWjn0ism6RJNisEmwWCTarJfIowWaxwG6VYLVIsKvbLRZlX2Q/oHzPVOqatinYBniVgCBFFngPQGo/DgRaIQVbgWAbpGCbEogCbZC6qzru8iFbgcEjIk1Ep3c85o9IrF+IDoQQCMsCIVn5jK0W5bPtsXku0KrUaDR2CgjhQKSKPkcJiF3WcyPrOV3Xu1zonV1Gu4TlnsN0KLIeDIURDvogfF7I/maln0okIFiCzZACrbAEWmANtaHdWYi27HK0ZQ9DIGsIrFYbbBaL9vdbI98xa+R7pG23SBhekIVspz5BzRRBIBAIIDMzE6+88gquuuoqbfucOXPQ1NSE1157rdfXMwjQiSYsi45wEJK1gOAPdmxTw0SbX6nNaA0ov7yVUBJGa0CpCYmuAVHXfUEZNqsEh9UCu9UCu025MGnPrZHnto7ntsh+h9UCl6PnJg/tucOKDJsVLkekBsNmQYs/hCa1P0h7EE2Rya/UR2UJaOtNbUH4B9CZlGJZIMMFPzLhh0tSHjPhQ6bkR4YUwEFRiBpRgqCkXPDVy6vaiiAh6oIrdTxIEmCRJFglJURZLOq6BIukXLAtkX0x65IEOeriHo5aQrKAHL09clxPOi6ESjBQnlu07dEXR/X8yt8maX9D52CI6H2R84Qi/02qtWfqulZjFu69nKm26p8m4ILvFejyXgO5hupeV3TkyBGEw2EUFxfHbC8uLsaePXu6HO/3++H3d0zJ6/XqMPaZKIWsFgmuSHX+yWQgff99wTC8vqDWRNPsUxZlvWO7V23C8QVjjgvLAgLKL0kB9Zd19HOhbVfXEdkXezGTYLUoFz6LJMFiib0IRh8nhHIhC0VdIEJyx3owLGsXulSQYUErXGiFK7bGvPPpe/wNZ54LXGehSGgY2CTsyWWPqgWyW5WaH3tU2O5pn1qDJAS074n6fYp+HpaVmoawHBuqgmEZGQb/v8PwcRyVlZV4+OGHjS4GEelA7XBZlGN0SfTXERiUoBAKi95/hXfdFDMRV3SoUTZAC0GRpx1hJ3Kc9iz2Ieo1Uc0UnY6RI1X1nZtK1F/7ImpdFh1V/GEhYI00n1gtFlilyC93qxKmuvs1b7NYtPAVFgLhcKdag8hnGH1BjK5tCIVlpQzdhMDoz6m7gAgADlv0RVzpqxNde6Y9tynbHFZL8u8Wa2K6B4GCggJYrVY0NMSOeW5oaMCQIUO6HL9o0SLcc8892nOv14uysrIuxxERGUmSpMiFBABOrtofSm8DuO9t7xwOB8aPH4/Nmzdr22RZxubNmzFx4sQuxzudTuTm5sYsRERElBpJaRq45557MGfOHJxzzjk477zzsGTJErS2tmLu3LnJOB0RERENUFKCwPXXX4/Dhw/jgQceQH19PcaNG4c33nijSwdCIiIiMhanGCYiIjpJDOQaqnsfASIiIjpxMAgQERGlMQYBIiKiNMYgQERElMYYBIiIiNIYgwAREVEaM/xeA52poxl58yEiIqL4qNfOeGYGMF0QaG5uBgDeb4CIiGiAmpub4Xa7+3Ws6SYUkmUZdXV1yMnJ0e1uUOqNjGprazlJUQ/4GfWNn1Hf+Bn1jZ9R3/gZ9a2nz0gIgebmZpSWlsJi6V/rv+lqBCwWC4YOHZqU9+ZNjfrGz6hv/Iz6xs+ob/yM+sbPqG/dfUb9rQlQsbMgERFRGmMQICIiSmNpEQScTicefPBBOJ1Oo4tiWvyM+sbPqG/8jPrGz6hv/Iz6pudnZLrOgkRERJQ6aVEjQERERN1jECAiIkpjDAJERERpjEGAiIgojaVFEFi6dCmGDx+OjIwMTJgwAR999JHRRTKNhx56CJIkxSyjRo0yuliGevfddzF9+nSUlpZCkiSsX78+Zr8QAg888ABKSkrgcrkwZcoUfP3118YU1iB9fUY/+9nPunyvfvzjHxtTWANUVlbi3HPPRU5ODoqKinDVVVehuro65hifz4d58+Zh8ODByM7OxjXXXIOGhgaDSpx6/fmMJk2a1OV79POf/9ygEqfesmXLcNZZZ2mTBk2cOBEbN27U9uv1HTrpg8BLL72Ee+65Bw8++CB27tyJsWPH4rLLLkNjY6PRRTONM888E4cOHdKW9957z+giGaq1tRVjx47F0qVLu93/xBNP4Omnn8Zzzz2HDz/8EFlZWbjsssvg8/lSXFLj9PUZAcCPf/zjmO/V6tWrU1hCY23btg3z5s3D9u3bsWnTJgSDQVx66aVobW3VjlmwYAFef/11rF27Ftu2bUNdXR1+8pOfGFjq1OrPZwQAt956a8z36IknnjCoxKk3dOhQPPbYY9ixYweqqqrwox/9CDNmzMDnn38OQMfvkDjJnXfeeWLevHna83A4LEpLS0VlZaWBpTKPBx98UIwdO9boYpgWALFu3TrtuSzLYsiQIeLJJ5/UtjU1NQmn0ylWr15tQAmN1/kzEkKIOXPmiBkzZhhSHjNqbGwUAMS2bduEEMp3xm63i7Vr12rHfPnllwKA+OCDD4wqpqE6f0ZCCHHxxReLX/ziF8YVyoQGDRok/uu//kvX79BJXSMQCASwY8cOTJkyRdtmsVgwZcoUfPDBBwaWzFy+/vprlJaW4tRTT8UNN9yA/fv3G10k06qpqUF9fX3Md8rtdmPChAn8TnWydetWFBUVYeTIkbj99ttx9OhRo4tkGI/HAwDIz88HAOzYsQPBYDDmezRq1CiUl5en7feo82ekevHFF1FQUIDRo0dj0aJFaGtrM6J4hguHw1izZg1aW1sxceJEXb9DprvpkJ6OHDmCcDiM4uLimO3FxcXYs2ePQaUylwkTJmDFihUYOXIkDh06hIcffhg//OEPsXv3buTk5BhdPNOpr68HgG6/U+o+UpoFfvKTn6CiogLffPMN/u3f/g1Tp07FBx98AKvVanTxUkqWZcyfPx8XXnghRo8eDUD5HjkcDuTl5cUcm67fo+4+IwCYPXs2hg0bhtLSUnz66ae4//77UV1djVdffdXA0qbWZ599hokTJ8Ln8yE7Oxvr1q3DGWecgV27dun2HTqpgwD1berUqdr6WWedhQkTJmDYsGF4+eWXccsttxhYMjqRzZw5U1sfM2YMzjrrLIwYMQJbt27F5MmTDSxZ6s2bNw+7d+9O+743venpM7rtttu09TFjxqCkpASTJ0/GN998gxEjRqS6mIYYOXIkdu3aBY/Hg1deeQVz5szBtm3bdD3HSd00UFBQAKvV2qUXZUNDA4YMGWJQqcwtLy8P3//+97F3716ji2JK6veG36n4nHrqqSgoKEi779Wdd96JDRs2YMuWLTG3Vx8yZAgCgQCamppijk/H71FPn1F3JkyYAABp9T1yOBz43ve+h/Hjx6OyshJjx47F73//e12/Qyd1EHA4HBg/fjw2b96sbZNlGZs3b8bEiRMNLJl5tbS04JtvvkFJSYnRRTGliooKDBkyJOY75fV68eGHH/I71YsDBw7g6NGjafO9EkLgzjvvxLp16/DOO++goqIiZv/48eNht9tjvkfV1dXYv39/2nyP+vqMurNr1y4ASJvvUXdkWYbf79f3O6Rvf0bzWbNmjXA6nWLFihXiiy++ELfddpvIy8sT9fX1RhfNFO69916xdetWUVNTI95//30xZcoUUVBQIBobG40ummGam5vFJ598Ij755BMBQPz2t78Vn3zyifjuu++EEEI89thjIi8vT7z22mvi008/FTNmzBAVFRWivb3d4JKnTm+fUXNzs/iXf/kX8cEHH4iamhrx9ttvix/84AfitNNOEz6fz+iip8Ttt98u3G632Lp1qzh06JC2tLW1acf8/Oc/F+Xl5eKdd94RVVVVYuLEiWLixIkGljq1+vqM9u7dKx555BFRVVUlampqxGuvvSZOPfVUcdFFFxlc8tRZuHCh2LZtm6ipqRGffvqpWLhwoZAkSbz11ltCCP2+Qyd9EBBCiGeeeUaUl5cLh8MhzjvvPLF9+3aji2Qa119/vSgpKREOh0Occsop4vrrrxd79+41uliG2rJliwDQZZkzZ44QQhlCuHjxYlFcXCycTqeYPHmyqK6uNrbQKdbbZ9TW1iYuvfRSUVhYKOx2uxg2bJi49dZb0yp8d/fZABDLly/Xjmlvbxd33HGHGDRokMjMzBRXX321OHTokHGFTrG+PqP9+/eLiy66SOTn5wun0ym+973vifvuu094PB5jC55CN998sxg2bJhwOByisLBQTJ48WQsBQuj3HeJtiImIiNLYSd1HgIiIiHrHIEBERJTGGASIiIjSGIMAERFRGmMQICIiSmMMAkRERGmMQYCIiCiNMQgQERGlMQYBIiKiNMYgQERElMYYBIiIiNIYgwAREVEa+/8SYACyLEEidQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.legend()\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Model loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10008678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 41s 153ms/step - loss: 0.0042 - accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00424534734338522, 0.9983521699905396]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665910a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 3s 156ms/step - loss: 0.2906 - accuracy: 0.9398\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_dataset, verbose=1)\n",
    "model.save(\"models/resnet50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8679ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, BatchNormalization, Flatten, Conv2D\n",
    "\n",
    "# Load pre-trained MobileNetV2 model without the top layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Hyperparameter tuning\n",
    "learning_rates = [1e-4, 1e-3]\n",
    "batch_sizes = [16, 32]\n",
    "dropout_rates = [0.3, 0.5]\n",
    "dense_units = [128, 256]  # Different dense layer sizes\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            for units in dense_units:\n",
    "                print(f\"Training with learning rate: {lr}, batch size: {batch_size}, dropout rate: {dropout_rate}, dense units: {units}\")\n",
    "                \n",
    "                # Modify the head layers dynamically\n",
    "                x = base_model.output\n",
    "                x = GlobalAveragePooling2D()(x)\n",
    "                x = Dense(units, activation='relu')(x)\n",
    "                x = BatchNormalization()(x)\n",
    "                x = Dropout(dropout_rate)(x)\n",
    "                x = Dense(units // 2, activation='relu')(x)  # Add another dense layer\n",
    "                x = Dropout(dropout_rate)(x)\n",
    "                predictions = Dense(len(np.unique(y)), activation='softmax')(x)\n",
    "                model = Model(inputs=base_model.input, outputs=predictions)\n",
    "                \n",
    "                # Compile the model\n",
    "                model.compile(optimizer=Adam(learning_rate=lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "                \n",
    "                # Early stopping\n",
    "                early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "                \n",
    "                # Train the model\n",
    "                history = model.fit(\n",
    "                    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=10,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                # Evaluate the model\n",
    "                val_accuracy = max(history.history['val_accuracy'])\n",
    "                if val_accuracy > best_accuracy:\n",
    "                    best_accuracy = val_accuracy\n",
    "                    best_model = model\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred = np.argmax(best_model.predict(X_val), axis=1)\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
